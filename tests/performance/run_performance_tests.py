#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ€§èƒ½æµ‹è¯•è¿è¡Œè„šæœ¬
æä¾›ä¾¿æ·çš„æ€§èƒ½æµ‹è¯•æ‰§è¡Œå’ŒæŠ¥å‘Šç”ŸæˆåŠŸèƒ½

ä½¿ç”¨æ–¹å¼:
python run_performance_tests.py --help
python run_performance_tests.py --quick
python run_performance_tests.py --full
python run_performance_tests.py --stress
python run_performance_tests.py --locust
"""

import os
import sys
import time
import argparse
import subprocess
import json
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))


class PerformanceTestRunner:
    """
    æ€§èƒ½æµ‹è¯•è¿è¡Œå™¨
    """
    
    def __init__(self):
        self.base_dir = Path(__file__).parent
        self.reports_dir = self.base_dir / 'reports'
        self.reports_dir.mkdir(exist_ok=True)
        
        # ç¡®ä¿åº”ç”¨ç¨‹åºæ­£åœ¨è¿è¡Œ
        self.app_url = 'http://localhost:5000'
        self.check_app_running()
    
    def check_app_running(self):
        """
        æ£€æŸ¥åº”ç”¨ç¨‹åºæ˜¯å¦æ­£åœ¨è¿è¡Œ
        """
        try:
            import requests
            response = requests.get(self.app_url, timeout=5)
            if response.status_code == 200:
                print(f"âœ… åº”ç”¨ç¨‹åºæ­£åœ¨è¿è¡Œ: {self.app_url}")
            else:
                print(f"âš ï¸ åº”ç”¨ç¨‹åºå“åº”å¼‚å¸¸: {response.status_code}")
        except Exception as e:
            print(f"âŒ æ— æ³•è¿æ¥åˆ°åº”ç”¨ç¨‹åº: {self.app_url}")
            print(f"é”™è¯¯: {e}")
            print("è¯·ç¡®ä¿åº”ç”¨ç¨‹åºæ­£åœ¨è¿è¡Œï¼Œç„¶åé‡æ–°æ‰§è¡Œæµ‹è¯•")
            print("å¯åŠ¨å‘½ä»¤: python app/app.py")
            sys.exit(1)
    
    def run_pytest_performance(self, test_type: str = 'basic') -> Dict[str, Any]:
        """
        è¿è¡Œpytestæ€§èƒ½æµ‹è¯•
        """
        print(f"\nğŸš€ å¼€å§‹è¿è¡Œ {test_type} æ€§èƒ½æµ‹è¯•...")
        
        # ç”ŸæˆæŠ¥å‘Šæ–‡ä»¶å
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        report_file = self.reports_dir / f'pytest_performance_{test_type}_{timestamp}.json'
        html_report = self.reports_dir / f'pytest_performance_{test_type}_{timestamp}.html'
        
        # æ„å»ºpytestå‘½ä»¤
        cmd = [
            'python', '-m', 'pytest',
            str(self.base_dir / 'test_performance.py'),
            '-v',
            '--tb=short'
        ]
        
        # å°è¯•æ·»åŠ HTMLæŠ¥å‘Šï¼ˆå¦‚æœæ’ä»¶å¯ç”¨ï¼‰
        try:
            import pytest_html
            cmd.extend([f'--html={html_report}', '--self-contained-html'])
        except ImportError:
            print("âš ï¸ pytest-html æ’ä»¶æœªå®‰è£…ï¼Œè·³è¿‡HTMLæŠ¥å‘Šç”Ÿæˆ")
        
        # å°è¯•æ·»åŠ JSONæŠ¥å‘Šï¼ˆå¦‚æœæ’ä»¶å¯ç”¨ï¼‰
        try:
            import pytest_json_report
            cmd.append(f'--json-report={report_file}')
        except ImportError:
            print("âš ï¸ pytest-json-report æ’ä»¶æœªå®‰è£…ï¼Œè·³è¿‡JSONæŠ¥å‘Šç”Ÿæˆ")
        
        # æ ¹æ®æµ‹è¯•ç±»å‹æ·»åŠ ç‰¹å®šå‚æ•°
        if test_type == 'quick':
            cmd.extend(['-k', 'test_homepage_response_time or test_products_page_response_time'])
        elif test_type == 'benchmark':
            cmd.extend(['--benchmark-only', '--benchmark-json=' + str(report_file.with_suffix('.benchmark.json'))])
        elif test_type == 'concurrent':
            cmd.extend(['-k', 'concurrent', '-n', '4'])
        elif test_type == 'stress':
            cmd.extend(['-k', 'stress'])
        elif test_type == 'memory':
            cmd.extend(['-k', 'memory'])
        
        # æ‰§è¡Œæµ‹è¯•
        start_time = time.time()
        try:
            result = subprocess.run(cmd, capture_output=True, text=True, cwd=project_root)
            execution_time = time.time() - start_time
            
            print(f"\nğŸ“Š æµ‹è¯•æ‰§è¡Œå®Œæˆï¼Œè€—æ—¶: {execution_time:.2f}ç§’")
            print(f"ğŸ“„ æŠ¥å‘Šæ–‡ä»¶: {html_report}")
            
            if result.returncode == 0:
                print("âœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡")
            else:
                print("âŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥")
                print("é”™è¯¯è¾“å‡º:")
                print(result.stderr)
            
            return {
                'type': f'pytest_{test_type}',
                'success': result.returncode == 0,
                'execution_time': execution_time,
                'report_file': str(html_report),
                'stdout': result.stdout,
                'stderr': result.stderr
            }
            
        except Exception as e:
            print(f"âŒ æµ‹è¯•æ‰§è¡Œå¤±è´¥: {e}")
            return {
                'type': f'pytest_{test_type}',
                'success': False,
                'error': str(e)
            }
    
    def run_locust_test(self, users: int = 10, spawn_rate: int = 2, duration: str = '60s') -> Dict[str, Any]:
        """
        è¿è¡ŒLocustè´Ÿè½½æµ‹è¯•
        """
        print(f"\nğŸ å¼€å§‹è¿è¡Œ Locust è´Ÿè½½æµ‹è¯•...")
        print(f"ç”¨æˆ·æ•°: {users}, ç”Ÿæˆé€Ÿç‡: {spawn_rate}/s, æŒç»­æ—¶é—´: {duration}")
        
        # ç”ŸæˆæŠ¥å‘Šæ–‡ä»¶å
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        csv_prefix = self.reports_dir / f'locust_{timestamp}'
        html_report = self.reports_dir / f'locust_report_{timestamp}.html'
        
        # æ„å»ºLocustå‘½ä»¤
        cmd = [
            'python', '-m', 'locust',
            '-f', str(self.base_dir / 'locustfile.py'),
            '--host', self.app_url,
            '--users', str(users),
            '--spawn-rate', str(spawn_rate),
            '--run-time', duration,
            '--headless',
            '--csv', str(csv_prefix),
            '--html', str(html_report)
        ]
        
        # æ‰§è¡Œæµ‹è¯•
        start_time = time.time()
        try:
            result = subprocess.run(cmd, capture_output=True, text=True, cwd=project_root)
            execution_time = time.time() - start_time
            
            print(f"\nğŸ“Š Locustæµ‹è¯•æ‰§è¡Œå®Œæˆï¼Œè€—æ—¶: {execution_time:.2f}ç§’")
            print(f"ğŸ“„ HTMLæŠ¥å‘Š: {html_report}")
            print(f"ğŸ“„ CSVæ•°æ®: {csv_prefix}_stats.csv")
            
            if result.returncode == 0:
                print("âœ… Locustæµ‹è¯•å®Œæˆ")
            else:
                print("âŒ Locustæµ‹è¯•å‡ºç°é—®é¢˜")
                print("é”™è¯¯è¾“å‡º:")
                print(result.stderr)
            
            return {
                'type': 'locust',
                'success': result.returncode == 0,
                'execution_time': execution_time,
                'html_report': str(html_report),
                'csv_prefix': str(csv_prefix),
                'stdout': result.stdout,
                'stderr': result.stderr
            }
            
        except Exception as e:
            print(f"âŒ Locustæµ‹è¯•æ‰§è¡Œå¤±è´¥: {e}")
            return {
                'type': 'locust',
                'success': False,
                'error': str(e)
            }
    
    def generate_summary_report(self, results: List[Dict[str, Any]]):
        """
        ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š
        """
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        summary_file = self.reports_dir / f'performance_summary_{timestamp}.json'
        
        summary = {
            'timestamp': timestamp,
            'total_tests': len(results),
            'successful_tests': sum(1 for r in results if r.get('success', False)),
            'failed_tests': sum(1 for r in results if not r.get('success', False)),
            'total_execution_time': sum(r.get('execution_time', 0) for r in results),
            'results': results
        }
        
        # ä¿å­˜æ±‡æ€»æŠ¥å‘Š
        with open(summary_file, 'w', encoding='utf-8') as f:
            json.dump(summary, f, indent=2, ensure_ascii=False)
        
        # æ‰“å°æ±‡æ€»ä¿¡æ¯
        print(f"\nğŸ“‹ æ€§èƒ½æµ‹è¯•æ±‡æ€»æŠ¥å‘Š")
        print(f"{'='*50}")
        print(f"æµ‹è¯•æ—¶é—´: {timestamp}")
        print(f"æ€»æµ‹è¯•æ•°: {summary['total_tests']}")
        print(f"æˆåŠŸæµ‹è¯•: {summary['successful_tests']}")
        print(f"å¤±è´¥æµ‹è¯•: {summary['failed_tests']}")
        print(f"æ€»æ‰§è¡Œæ—¶é—´: {summary['total_execution_time']:.2f}ç§’")
        print(f"æ±‡æ€»æŠ¥å‘Š: {summary_file}")
        
        # åˆ—å‡ºæ‰€æœ‰æŠ¥å‘Šæ–‡ä»¶
        print(f"\nğŸ“ ç”Ÿæˆçš„æŠ¥å‘Šæ–‡ä»¶:")
        for result in results:
            if 'report_file' in result:
                print(f"  - {result['type']}: {result['report_file']}")
            if 'html_report' in result:
                print(f"  - {result['type']}: {result['html_report']}")
    
    def install_dependencies(self):
        """
        å®‰è£…æ€§èƒ½æµ‹è¯•ä¾èµ–
        """
        print("ğŸ“¦ å®‰è£…æ€§èƒ½æµ‹è¯•ä¾èµ–...")
        
        dependencies = [
            'pytest',
            'pytest-benchmark',
            'pytest-xdist',
            'pytest-html',
            'pytest-json-report',
            'locust',
            'requests'
        ]
        
        for dep in dependencies:
            try:
                subprocess.run(['pip', 'install', dep], check=True, capture_output=True)
                print(f"âœ… {dep} å®‰è£…æˆåŠŸ")
            except subprocess.CalledProcessError as e:
                print(f"âŒ {dep} å®‰è£…å¤±è´¥: {e}")
    
    def run_quick_test(self):
        """
        è¿è¡Œå¿«é€Ÿæ€§èƒ½æµ‹è¯•
        """
        print("ğŸƒâ€â™‚ï¸ è¿è¡Œå¿«é€Ÿæ€§èƒ½æµ‹è¯•...")
        results = []
        results.append(self.run_pytest_performance('quick'))
        self.generate_summary_report(results)
    
    def run_full_test(self):
        """
        è¿è¡Œå®Œæ•´æ€§èƒ½æµ‹è¯•
        """
        print("ğŸƒâ€â™‚ï¸ è¿è¡Œå®Œæ•´æ€§èƒ½æµ‹è¯•...")
        results = []
        
        # åŸºç¡€æ€§èƒ½æµ‹è¯•
        results.append(self.run_pytest_performance('basic'))
        
        # åŸºå‡†æµ‹è¯•
        results.append(self.run_pytest_performance('benchmark'))
        
        # å¹¶å‘æµ‹è¯•
        results.append(self.run_pytest_performance('concurrent'))
        
        # å†…å­˜æ³„æ¼æ£€æµ‹
        results.append(self.run_pytest_performance('memory'))
        
        self.generate_summary_report(results)
    
    def run_stress_test(self):
        """
        è¿è¡Œå‹åŠ›æµ‹è¯•
        """
        print("ğŸ’ª è¿è¡Œå‹åŠ›æµ‹è¯•...")
        results = []
        
        # pytestå‹åŠ›æµ‹è¯•
        results.append(self.run_pytest_performance('stress'))
        
        # Locustè´Ÿè½½æµ‹è¯•
        results.append(self.run_locust_test(users=20, spawn_rate=5, duration='120s'))
        
        self.generate_summary_report(results)
    
    def run_locust_only(self, users: int = 10, duration: str = '60s'):
        """
        ä»…è¿è¡ŒLocustæµ‹è¯•
        """
        print("ğŸ è¿è¡ŒLocustè´Ÿè½½æµ‹è¯•...")
        results = []
        results.append(self.run_locust_test(users=users, duration=duration))
        self.generate_summary_report(results)


def main():
    parser = argparse.ArgumentParser(description='å•†åŸç³»ç»Ÿæ€§èƒ½æµ‹è¯•è¿è¡Œå™¨')
    parser.add_argument('--quick', action='store_true', help='è¿è¡Œå¿«é€Ÿæ€§èƒ½æµ‹è¯•')
    parser.add_argument('--full', action='store_true', help='è¿è¡Œå®Œæ•´æ€§èƒ½æµ‹è¯•')
    parser.add_argument('--stress', action='store_true', help='è¿è¡Œå‹åŠ›æµ‹è¯•')
    parser.add_argument('--locust', action='store_true', help='ä»…è¿è¡ŒLocustè´Ÿè½½æµ‹è¯•')
    parser.add_argument('--install-deps', action='store_true', help='å®‰è£…æµ‹è¯•ä¾èµ–')
    parser.add_argument('--users', type=int, default=10, help='Locustæµ‹è¯•ç”¨æˆ·æ•° (é»˜è®¤: 10)')
    parser.add_argument('--duration', default='60s', help='Locustæµ‹è¯•æŒç»­æ—¶é—´ (é»˜è®¤: 60s)')
    
    args = parser.parse_args()
    
    runner = PerformanceTestRunner()
    
    if args.install_deps:
        runner.install_dependencies()
        return
    
    if args.quick:
        runner.run_quick_test()
    elif args.full:
        runner.run_full_test()
    elif args.stress:
        runner.run_stress_test()
    elif args.locust:
        runner.run_locust_only(users=args.users, duration=args.duration)
    else:
        print("è¯·é€‰æ‹©ä¸€ä¸ªæµ‹è¯•é€‰é¡¹:")
        print("  --quick     å¿«é€Ÿæ€§èƒ½æµ‹è¯•")
        print("  --full      å®Œæ•´æ€§èƒ½æµ‹è¯•")
        print("  --stress    å‹åŠ›æµ‹è¯•")
        print("  --locust    Locustè´Ÿè½½æµ‹è¯•")
        print("  --install-deps  å®‰è£…æµ‹è¯•ä¾èµ–")
        print("\nç¤ºä¾‹:")
        print("  python run_performance_tests.py --quick")
        print("  python run_performance_tests.py --locust --users 20 --duration 120s")


if __name__ == '__main__':
    main()